{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rebelclause/AI/blob/master/Markov_Chain_NLP.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "source": [
        "# IMPORTANT: RUN THIS CELL IN ORDER TO IMPORT YOUR KAGGLE DATA SOURCES,\n",
        "# THEN FEEL FREE TO DELETE THIS CELL.\n",
        "# NOTE: THIS NOTEBOOK ENVIRONMENT DIFFERS FROM KAGGLE'S PYTHON\n",
        "# ENVIRONMENT SO THERE MAY BE MISSING LIBRARIES USED BY YOUR\n",
        "# NOTEBOOK.\n",
        "import kagglehub\n",
        "idevji1_sherlock_holmes_stories_path = kagglehub.dataset_download('idevji1/sherlock-holmes-stories')\n",
        "\n",
        "print('Data source import complete.')\n"
      ],
      "metadata": {
        "id": "Nin0jS0t-zue"
      },
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {
        "id": "AT19NhmE-zui"
      },
      "cell_type": "markdown",
      "source": [
        "<img src=\"https://drive.google.com/uc?export=view&amp;id=1zSJwAUxWv5bxyYLmYPNi-s6M_Wq5iWXh\">"
      ]
    },
    {
      "metadata": {
        "id": "zqlOglW3-zul"
      },
      "cell_type": "markdown",
      "source": [
        "## Importing tools"
      ]
    },
    {
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "trusted": true,
        "id": "kn25Y5lL-zum"
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "import re\n",
        "import string\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "import random"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "8ZQEnanq-zum"
      },
      "cell_type": "markdown",
      "source": [
        "## Reading every Sherlock Holmes adventure!"
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "id": "BhQt5klN-zun"
      },
      "cell_type": "code",
      "source": [
        "story_path = \"/kaggle/input/sherlock-holmes-stories/sherlock/sherlock/\"\n",
        "\n",
        "def read_all_stories(story_path):\n",
        "    txt = []\n",
        "    for _, _, files in os.walk(story_path):\n",
        "        for file in files:\n",
        "            with open(story_path+file) as f:\n",
        "                for line in f:\n",
        "                    line = line.strip()\n",
        "                    if line=='----------': break\n",
        "                    if line!='':txt.append(line)\n",
        "    return txt\n",
        "\n",
        "stories = read_all_stories(story_path)\n",
        "print(\"number of lines = \", len(stories))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "DNVu-Xo2-zun"
      },
      "cell_type": "markdown",
      "source": [
        "## Cleaning the text"
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "id": "7W3uYmTW-zuo"
      },
      "cell_type": "code",
      "source": [
        "def clean_txt(txt):\n",
        "    cleaned_txt = []\n",
        "    for line in txt:\n",
        "        line = line.lower()\n",
        "        line = re.sub(r\"[,.\\\"\\'!@#$%^&*(){}?/;`~:<>+=-\\\\]\", \"\", line)\n",
        "        tokens = word_tokenize(line)\n",
        "        words = [word for word in tokens if word.isalpha()]\n",
        "        cleaned_txt+=words\n",
        "    return cleaned_txt\n",
        "\n",
        "cleaned_stories = clean_txt(stories)\n",
        "print(\"number of words = \", len(cleaned_stories))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "gDpdXao8-zup"
      },
      "cell_type": "markdown",
      "source": [
        "## Creating the Markov Model"
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "id": "6d8nlpZG-zup"
      },
      "cell_type": "code",
      "source": [
        "def make_markov_model(cleaned_stories, n_gram=2):\n",
        "    markov_model = {}\n",
        "    for i in range(len(cleaned_stories)-n_gram-1):\n",
        "        curr_state, next_state = \"\", \"\"\n",
        "        for j in range(n_gram):\n",
        "            curr_state += cleaned_stories[i+j] + \" \"\n",
        "            next_state += cleaned_stories[i+j+n_gram] + \" \"\n",
        "        curr_state = curr_state[:-1]\n",
        "        next_state = next_state[:-1]\n",
        "        if curr_state not in markov_model:\n",
        "            markov_model[curr_state] = {}\n",
        "            markov_model[curr_state][next_state] = 1\n",
        "        else:\n",
        "            if next_state in markov_model[curr_state]:\n",
        "                markov_model[curr_state][next_state] += 1\n",
        "            else:\n",
        "                markov_model[curr_state][next_state] = 1\n",
        "\n",
        "    # calculating transition probabilities\n",
        "    for curr_state, transition in markov_model.items():\n",
        "        total = sum(transition.values())\n",
        "        for state, count in transition.items():\n",
        "            markov_model[curr_state][state] = count/total\n",
        "\n",
        "    return markov_model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "id": "RsU2KFTI-zuq"
      },
      "cell_type": "code",
      "source": [
        "markov_model = make_markov_model(cleaned_stories)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "id": "KMCGpdhn-zuq"
      },
      "cell_type": "code",
      "source": [
        "print(\"number of states = \", len(markov_model.keys()))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "id": "OAdU9CuJ-zuq"
      },
      "cell_type": "code",
      "source": [
        "print(\"All possible transitions from 'the game' state: \\n\")\n",
        "print(markov_model['the game'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "UtE5weZX-zur"
      },
      "cell_type": "markdown",
      "source": [
        "## Generating Sherlock Holmes stories!"
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "id": "hgdEFz1v-zur"
      },
      "cell_type": "code",
      "source": [
        "def generate_story(markov_model, limit=100, start='my god'):\n",
        "    n = 0\n",
        "    curr_state = start\n",
        "    next_state = None\n",
        "    story = \"\"\n",
        "    story+=curr_state+\" \"\n",
        "    while n<limit:\n",
        "        next_state = random.choices(list(markov_model[curr_state].keys()),\n",
        "                                    list(markov_model[curr_state].values()))\n",
        "\n",
        "        curr_state = next_state[0]\n",
        "        story+=curr_state+\" \"\n",
        "        n+=1\n",
        "    return story"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "id": "r9s8PY-K-zur"
      },
      "cell_type": "code",
      "source": [
        "for i in range(20):\n",
        "    print(str(i)+\". \", generate_story(markov_model, start=\"dear holmes\", limit=8))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "id": "Gdiz9Iun-zus"
      },
      "cell_type": "code",
      "source": [
        "for i in range(20):\n",
        "    print(str(i)+\". \", generate_story(markov_model, start=\"my dear\", limit=8))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "id": "zeuDDH_--zus"
      },
      "cell_type": "code",
      "source": [
        "for i in range(20):\n",
        "    print(str(i)+\". \", generate_story(markov_model, start=\"i would\", limit=8))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "id": "MfhDenCb-zus"
      },
      "cell_type": "code",
      "source": [
        "print(generate_story(markov_model, start=\"the case\", limit=100))"
      ],
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "version": "3.6.4",
      "file_extension": ".py",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "name": "python",
      "mimetype": "text/x-python"
    },
    "colab": {
      "name": "Markov Chain NLP",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}